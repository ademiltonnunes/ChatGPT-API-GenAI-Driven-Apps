# Real-time Speech to Text to Speech: Building Your AI-Based Alexa

This project aims to implement an AI-Based "Alexa," enabling voice interaction with ChatGPT using Whisper for speech-to-text and Google Text to Speech (GTTS) for audio responses.

## Introduction

Enhance your conversational experience with a voice-activated ChatGPT! This project leverages Whisper to capture and transcribe voice input, integrates with ChatGPT for text-based responses, and employs GTTS to convert responses into audio.

## Features

- **Whisper Integration:** Utilizes Whisper for voice capture and transcription. Whisper is an ASR system (automatic speech recognition) trained on 680,000 hours of multilingual data. It offers real-time integration, transcribing voice-audio into text.

- **ChatGPT Integration:** Seamlessly integrates with the ChatGPT OpenAI text-davinci-002 model to provide accurate and context-aware answers to user queries.

- **GTTS Integration:** Employs Google Text to Speech (GTTS) to convert text responses generated by ChatGPT into audio format, creating a natural and human-like voice output.

## Technologies Used

- **Python:** The programming language used for development.
- **Whisper:** A speech-to-text tool that captures voice and transcribes it into text.
- **GTTS (Google Text to Speech):** Transforms text into audio for a natural voice output.
- **Click Library:** Used for handling command-line parameters and attribute parameters.

## Getting Started

Follow these steps to set up your project with a virtual environment:

1. **Install Python:** [Download and install Python](https://www.python.org/downloads/).

2. **Clone this repository:**

   ```bash
   git clone https://github.com/ademiltonnunes/ChatGPT-API-GenAI-Driven-Apps.git

3.  Navigate into the project directory
      ```bash
        cd Real-time-Speech-to-Text-to-Speech

5. Create a new virtual environment:

   ```bash
   python -m venv venv
   ```
6. Active the new virtual environment:
   - Linux:
    ```bash
      . venv/bin/activate
     ```
   - Windows:
   ```bash
   .\venv\Scripts\Activate
    ```
7. Install the module ffmpeg:
   - Windows:
   ```bash 
    choco install ffmpeg
   ```
   - Linux:
   ```bash
   sudo apt install ffmpeg
   ```
8. Install the requirements:

   ```bash
   pip install -r requirements.txt
   ```

9. Add your [API key](https://beta.openai.com/account/api-keys) to the `.env` file.

10. Run the app:

   ```bash
   python speechRecognation.py
   ```

The app should now be running on the console.

## Project Flow
**1. User Records Audio**: The user initiates interaction by recording audio using the designated wake word "Hey computer". Parameters like Energy, Pause, and Dynamic can be configured for sound quality.:
  - Energy: configures the magnitude of the sound or signal in a specific segment audio.
  - Pause: Configures how long there should be a pause between words, if the pause is longer than the configured value, the audio is submitted to the next steps.
  - Dynamic: Configures changes in loudness or intensity over time.
This audio will be saved in a audio query which will be the input to the step of “Audio Transcription with Whisper”.

**2. Audio Transcription with Whisper**: Whisper captures the recorded voice and transcribes it into text, preparing it for sending to ChatGPT. At the time of transcription, some words may be disregarded and excluded, such as:
 - Wake word: Wake word does not need to be in the audio transcription.
 - Stop word:are words that have no semantic meaning but can be present in the audio, an example is the word "like", some people with language addiction can say this word all the time when they are speaking.

**3. ChatGPT Processes Text**: The transcribed text is submitted to ChatGPT, which analyzes the content and generates a text-based response. ChatGPT response can answer user prompt or it may have default responses if the user's audio doesn't make sense. Default response are:
  - "I'm sorry, I don't know the answer to that"
  -  "I'm not sure I understand"
  -  "I'm not sure I can answer that",
  -  "Please repeat the question in a different way"

**4. Text-to-Audio Conversion with GTTS**: GTTS takes the generated text response and converts it into audio, providing a natural and human-like voice.

**5. Audio Execution**: The final audio response is played through the computer speakers, delivering the answer to the user's question.

## Usage
Once the application is running, say the wake word "Hey computer," followed by your question recorded by the computer microphone. After processing, the application should answer the question in voice, played through the computer speakers.
